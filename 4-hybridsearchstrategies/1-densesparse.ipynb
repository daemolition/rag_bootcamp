{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58fb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8180bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: sample Documents\n",
    "docs = [\n",
    "    Document(page_content=\"Langchain helps to build LLM applications\"),\n",
    "    Document(page_content=\"Langchain is a framework for building language models\"),\n",
    "    Document(page_content=\"Pinecone is a vector database that stores embeddings of text documents\"),\n",
    "    Document(page_content=\"The Eiffel tower is located in Paris, France\"),\n",
    "    Document(page_content=\"Langchain is used to build applications that interact with LLMs\"),\n",
    "] \n",
    "\n",
    "### Dense retriever\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "dense_vectorestore = FAISS.from_documents(docs, embedding_model)\n",
    "dense_retriever = dense_vectorestore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5579cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sparse Retriever (BM25)\n",
    "spares_retriever = BM25Retriever.from_documents(docs)\n",
    "spares_retriever.k=3 ## Top k documents to retriever\n",
    "\n",
    "## Step4: Combine with ensamble retriever\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[dense_retriever, spares_retriever],\n",
    "    weights=[0.70, 0.3]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326b0e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Document 1:\n",
      "Langchain is used to build applications that interact with LLMs\n",
      "\n",
      " Document 2:\n",
      "Langchain helps to build LLM applications\n",
      "\n",
      " Document 3:\n",
      "Langchain is a framework for building language models\n",
      "\n",
      " Document 4:\n",
      "Pinecone is a vector database that stores embeddings of text documents\n",
      "\n",
      " Document 5:\n",
      "The Eiffel tower is located in Paris, France\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "query = \"How can i build an application using LLMs?\"\n",
    "result = hybrid_retriever.invoke(query)\n",
    "\n",
    "# Step 6\n",
    "for i, doc in enumerate(result):\n",
    "    print(f\"\\n Document {i+1}:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b06f4",
   "metadata": {},
   "source": [
    "### RAG Pipeline with hybrid retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc531cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92251625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Prompt template\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "# Step 6: LLM\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:4b-it-q4_K_M\",\n",
    "    num_ctx=32768\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9641a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x714189224590>, search_kwargs={}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x714128f73e30>, k=3)], weights=[0.7, 0.3]), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nAnswer the question based on the context below.\\n\\nContext:\\n{context}\\n\\nQuestion: {input}\\n')\n",
       "            | ChatOllama(model='gemma3:4b-it-q4_K_M', num_ctx=32768)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create stuff document chain\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "## Create a full rag chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=hybrid_retriever,\n",
    "    combine_docs_chain=document_chain\n",
    ")\n",
    "\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45f4680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " According to the context, you can build an app using LLMs with Langchain. Langchain is a framework for building language models and is used to build applications that interact with LLMs.\n",
      "\n",
      " Source Documents:\n",
      "\n",
      "Doc 1: Langchain helps to build LLM applications\n",
      "\n",
      "Doc 2: Langchain is used to build applications that interact with LLMs\n",
      "\n",
      "Doc 3: Langchain is a framework for building language models\n",
      "\n",
      "Doc 4: Pinecone is a vector database that stores embeddings of text documents\n",
      "\n",
      "Doc 5: The Eiffel tower is located in Paris, France\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Ask a question\n",
    "query = {'input': 'How can I build an app using LLMs?'}\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# Step 10: Output\n",
    "print(\"Answer:\\n\", response[\"answer\"])\n",
    "print(\"\\n Source Documents:\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\"\\nDoc {i+1}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba840e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
