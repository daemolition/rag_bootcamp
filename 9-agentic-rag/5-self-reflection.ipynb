{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42938ff",
   "metadata": {},
   "source": [
    "# What is selfrecflection in RAG\n",
    "Self-Reflection = LLM evaluates its own output: \"Is this clear, complete and accurate?\"\n",
    "\n",
    "1. Generates an initial answer using retrieved context\n",
    "2. Reflects on that answer with a dedicated self-critic LLM step\n",
    "3. If unsatisfied, it can revise the query, retrieve again, or regenerate the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba38b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.tools import Tool, tool, StructuredTool\n",
    "from langchain_core.documents import Document\n",
    "from langchain.agents import create_agent\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7557f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = TextLoader(\n",
    "    \"research_notes.txt\",\n",
    "    encoding=\"utf-8\"\n",
    ").load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97d646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3:4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ff22619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGReflectionState(BaseModel):\n",
    "    question: str\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\"\n",
    "    reflection: str = \"\"\n",
    "    revised: bool = False\n",
    "    attempts: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f35e5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    docs = retriever.invoke(state.question)\n",
    "    return state.model_copy(update={\"retrieved_docs\": docs})\n",
    "\n",
    "def generate_answer(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    context  = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "        Use the follow context to answer the question:\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Question:\n",
    "        {state.question}\n",
    "    \"\"\"\n",
    "    \n",
    "    answer = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"answer\": answer, \"attempts\": state.attempts + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae1df3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_answer(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "       Reflect on the following answer to see if it fully addresses the question:\n",
    "       Satte YES if it is complete and correct, or NO with an explanation.\n",
    "       \n",
    "       Question: {state.question}\n",
    "       \n",
    "       Answer: {state.answer}\n",
    "       \n",
    "       REspond like:\n",
    "       Reflection: YES or NO\n",
    "       \n",
    "       Explanations: ...\n",
    "    \"\"\"\n",
    "    \n",
    "    result = llm.invoke(prompt).content\n",
    "    is_ok = \"reflection: yes\" in result.lower()\n",
    "    return state.model_copy(update={\"reflection\": result, \"revised\": not is_ok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beaf61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3abec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(RAGReflectionState)\n",
    "\n",
    "builder.add_node(\"retriever\", retrieve_docs)\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "builder.add_node(\"reflector\", reflect_answer)\n",
    "builder.add_node(\"done\", finalize)\n",
    "\n",
    "builder.set_entry_point(\"retriever\")\n",
    "\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", \"reflector\")\n",
    "builder.add_conditional_edges(\n",
    "    \"reflector\",\n",
    "    lambda s: \"done\" if not s.revised or s.attempts >=2 else \"retriever\"\n",
    ")\n",
    "builder.add_edge(\"done\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6e49916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Answer:\n",
      " Based **strictly on the provided context**, there is **no mention of \"agnet loops\"** in the text. This appears to be a **typo or misstatement** (likely meant to be \"agent loops\" or \"agent systems\"). The context describes several AI systems and evaluation protocols but **does not discuss \"agnet loops\" at all**.\n",
      "\n",
      "However, I can address what *is* relevant in the context to clarify your likely intent:\n",
      "\n",
      "---\n",
      "\n",
      "### üîç Key Clarification & What the Context *Does* Say About Agent Systems:\n",
      "1. **The context mentions \"retrieval-agent reasoning\"** (Section 3):\n",
      "   - This refers to **agent-based systems** that chain tools (e.g., SQL queries + Wikipedia) for dynamic reasoning.\n",
      "   - **Benefit**: Enables multi-step workflows (e.g., \"Give me customer insights from SQL, verify with wiki\") by combining tools in a logical sequence.\n",
      "\n",
      "2. **No \"agnet loops\" are described**:\n",
      "   - The term \"agnet\" is not used in AI literature or this context.\n",
      "   - The context discusses **agent systems** (e.g., retrieval agents), **not loops** (cyclic processes) or \"agnet\" as a concept.\n",
      "\n",
      "3. **Why \"agnet\" likely isn't a real term**:\n",
      "   - In AI, \"agent\" (e.g., *retrieval agents*, *reasoning agents*) is standard.\n",
      "   - \"Loop\" implies cyclic processes (e.g., feedback loops), but the context describes **one-off agent workflows**, not loops.\n",
      "   - **No experiments, metrics, or benefits for \"agnet loops\" exist in this context**.\n",
      "\n",
      "---\n",
      "\n",
      "### ‚úÖ Correct Answer Based on Context:\n",
      "**The context does not provide any information about \"agnet loops\"** because:\n",
      "- The term **does not appear** in the given text.\n",
      "- The context discusses **agent systems** (e.g., tool-augmented prompting with retrieval agents), but **not loops** or \"agnet\" as a concept.\n",
      "- If you meant **\"agent loops\"** (e.g., feedback loops in agent systems), the context **does not describe them** either.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå Recommendation:\n",
      "If you're interested in **agent-based systems** (as described in the context), here's what *is* covered:\n",
      "| **Concept**          | **Benefit in Context**                                                                 |\n",
      "|-----------------------|-------------------------------------------------------------------------------------|\n",
      "| **Tool-augmented agents** | Enables dynamic reasoning by chaining tools (SQL + Wikipedia) for customer insights. |\n",
      "| **Retrieval agents**   | Handles multi-step tasks (e.g., verify facts across sources) without manual intervention. |\n",
      "\n",
      "But for **\"agnet loops\"**‚Äî**this is not addressed in the context**. Double-check the term:  \n",
      "- ‚úÖ **Likely meant**: *Agent systems* (as in the context).  \n",
      "- ‚ùå **Not in context**: *Agnet loops* (a non-standard term with no relevance here).\n",
      "\n",
      "If you meant something else (e.g., \"agent loops\" in reinforcement learning), the context **does not cover it**. I‚Äôd be happy to help refine your question if you clarify! \n",
      "\n",
      "*(Source: Strictly limited to the provided context)*\n",
      "\n",
      " Reflection Log:\\n Reflection: YES\n",
      "\n",
      "Explanations: The answer fully addresses the question by explicitly confirming that **\"agnet loops\" do not exist in the provided context** (a critical point since the term is non-standard and likely a typo). It correctly identifies the intended concept (\"agent systems\" vs. \"loops\") and provides *actual benefits from the context* for relevant agent-related concepts (e.g., tool-augmented reasoning, multi-step workflows), while rigorously avoiding speculation about non-existent \"agnet loops.\" Crucially, it adheres to the constraint of \"strictly based on the provided context\" by:  \n",
      "1. Declaring the term \"agnet\" has no relevance in AI literature or the context,  \n",
      "2. Clarifying that the context discusses *one-off agent workflows* (not loops),  \n",
      "3. Explicitly stating **no benefits for \"agnet loops\" exist in this context** (since the term isn‚Äôt defined).  \n",
      "This response is complete, accurate, and directly answers the question without overreaching‚Äîmaking it a correct and thorough reflection of the context.\n",
      "Total Attempts: 1\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What are the benefits of agnet loops in AI?\"\n",
    "init_state = RAGReflectionState(question=user_query)\n",
    "result = graph.invoke(init_state)\n",
    "\n",
    "print(\"\\n Final Answer:\\n\", result['answer'])\n",
    "print(\"\\n Reflection Log:\\\\n\", result['reflection'])\n",
    "print(\"Total Attempts:\", result['attempts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f25c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
