{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2103176",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a pwoerful technique that combines the capabilities of large\n",
    "language models with external knowledge retrievla. This notebook will walk you through building a complete RAG system using:  \n",
    "\n",
    "- LangChain: A framework fordeveloping applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitue with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "275b7a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "acb28527",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langchain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# vectorestore\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3672213f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning involves teaching computers to learn from and make predictions on data. It is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models to enable machines to improve their performance on specific tasks over time.',\n",
       " 'Deep learning is a type of machine learning that uses neural networks with multiple layers to learn and extract features from complex data, such as images, sound, and text. It has achieved state-of-the-art results in many domains, including image recognition, natural language processing, and speech recognition.',\n",
       " 'Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sample data document\n",
    "sample_docs = [\n",
    "    \"Machine learning involves teaching computers to learn from and make predictions on data. It is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models to enable machines to improve their performance on specific tasks over time.\",\n",
    "    \"Deep learning is a type of machine learning that uses neural networks with multiple layers to learn and extract features from complex data, such as images, sound, and text. It has achieved state-of-the-art results in many domains, including image recognition, natural language processing, and speech recognition.\",\n",
    "    \"Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.\"\n",
    "]\n",
    "\n",
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39d70dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save sample documents to files\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"data/doc_{i}.txt\", \"w\") as file:\n",
    "        file.write(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0abc72",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13152624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 3 documents\n",
      "\n",
      "First Document:\n",
      "Embeddings are numerical representations of words or phrases that capture their meaning and context....\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load documents from directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data/\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\n",
    "        'encoding':'utf-8'\n",
    "    }\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded: {len(documents)} documents\")\n",
    "print(f\"\\nFirst Document:\")\n",
    "print(documents[0].page_content[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cf74e",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0de0f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 chunks from 3 documents\n",
      "\n",
      "Chunk example:\n",
      "Content: Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as in...\n",
      "Metadata: {'source': 'data/doc_2.txt'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]   \n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk example:\")\n",
    "print(f\"Content: {chunks[0].page_content[:150]}...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c05aa2",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "745e7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Embeddings Inference\n",
    "embeddings = HuggingFaceEndpointEmbeddings(model=\"http://localhost:8080\")\n",
    "vector = embeddings.embed_documents([text.page_content for text in chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2133c43",
   "metadata": {},
   "source": [
    "## Vetorstore\n",
    "Initialize ChromaDB and Store the chunks in vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8541bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorestrore created with 15 vectors\n",
      "Persited to: ./chromadb\n"
     ]
    }
   ],
   "source": [
    "## Create ChromaDB vectorstore\n",
    "persist_directory=\"./chromadb\"\n",
    "\n",
    "## Initialize ChromaDB\n",
    "vectore_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEndpointEmbeddings(model=\"http://localhost:8080\"),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vectorestrore created with {vectore_store._collection.count()} vectors\")\n",
    "print(f\"Persited to: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1be1a",
   "metadata": {},
   "source": [
    "### Test the similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed7fc581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine learning involves teaching computers to learn from and make predictions on data. It is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models to enable machines to improve their performance on specific tasks over time.'),\n",
       "  0.32409441471099854),\n",
       " (Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine learning involves teaching computers to learn from and make predictions on data. It is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models to enable machines to improve their performance on specific tasks over time.'),\n",
       "  0.32409441471099854),\n",
       " (Document(metadata={'source': 'data/doc_0.txt'}, page_content='Machine learning involves teaching computers to learn from and make predictions on data. It is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models to enable machines to improve their performance on specific tasks over time.'),\n",
       "  0.3243904411792755)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Advanced similarity search\n",
    "\n",
    "query = \"What is machine learning\"\n",
    "\n",
    "result = vectore_store.similarity_search_with_score(query, k=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2ead7",
   "metadata": {},
   "source": [
    "### Understandig similarity score\n",
    "The similarity score represents how closly related a document chunk is to your query. The scoring depends on the distance\n",
    "metric used.\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)  \n",
    "- Score of 0 = identical vectors  \n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):  \n",
    "\n",
    "- Higher scores = More similar  \n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9bec6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize LLM, RAG Chain, Prompt Template, Query the RAG System\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",    \n",
    "    temperature=0.2,\n",
    "    reasoning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "55962764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) are a type of artificial intelligence (AI) designed to process and generate human-like language. They're a crucial component of natural language processing (NLP), which enables computers to understand, interpret, and respond to human language.\n",
      "\n",
      "**Key characteristics:**\n",
      "\n",
      "1. **Scale**: LLMs are trained on massive datasets, often in the order of tens or hundreds of gigabytes.\n",
      "2. **Complexity**: These models have millions or even billions of parameters, allowing them to capture subtle patterns and relationships in language.\n",
      "3. **Depth**: LLMs typically consist of multiple layers, each processing different aspects of the input data.\n",
      "\n",
      "**How they work:**\n",
      "\n",
      "1. **Training**: LLMs are trained on a large corpus of text data using various algorithms, such as masked language modeling or next sentence prediction.\n",
      "2. **Self-supervised learning**: During training, the model learns to predict missing words or entire sentences in the input data.\n",
      "3. **Fine-tuning**: After initial training, the model can be fine-tuned on specific tasks, like sentiment analysis or question answering.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "1. **Language translation**: LLMs can translate text from one language to another with high accuracy.\n",
      "2. **Text summarization**: These models can summarize long documents into concise, informative summaries.\n",
      "3. **Chatbots and virtual assistants**: LLMs power conversational interfaces like Siri, Alexa, or Google Assistant.\n",
      "4. **Content generation**: They can generate human-like text for various applications, such as articles, stories, or even entire books.\n",
      "\n",
      "**Examples of popular Large Language Models:**\n",
      "\n",
      "1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google in 2018, BERT is a widely used LLM that has achieved state-of-the-art results on many NLP tasks.\n",
      "2. **RoBERTa**: A variant of BERT developed by Facebook AI Research (FAIR) in 2019, which further improves performance on various NLP benchmarks.\n",
      "3. **XLNet**: Another popular LLM developed by Google and Carnegie Mellon University in 2019, which uses a novel permutation-based approach to improve language understanding.\n",
      "\n",
      "**Challenges and limitations:**\n",
      "\n",
      "1. **Data quality and availability**: Large datasets are often biased or incomplete, affecting the model's performance.\n",
      "2. **Computational resources**: Training and fine-tuning LLMs require significant computational power and memory.\n",
      "3. **Explainability and interpretability**: It can be challenging to understand why a particular output was generated by an LLM.\n",
      "\n",
      "Overall, Large Language Models have revolutionized the field of NLP, enabling computers to process and generate human-like language with unprecedented accuracy. However, their development and application also raise important questions about data quality, bias, and accountability."
     ]
    }
   ],
   "source": [
    "test_response = llm.stream(\"What are Large Language Models\")\n",
    "\n",
    "for text in test_response:\n",
    "    print(text.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230c60c",
   "metadata": {},
   "source": [
    "## Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4060ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "59873157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert vectorestore to retriever\n",
    "retriever = vectore_store.as_retriever(\n",
    "    search_kwarg={\"k\":3} # Retrieve top 3 chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7dabc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say tha you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f573363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say tha you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.1:8b', reasoning=False, temperature=0.2)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create document chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb75137",
   "metadata": {},
   "source": [
    "**This chain**\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b44956a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What can you tell me about embedding?',\n",
       " 'context': [Document(metadata={'source': 'data/doc_2.txt'}, page_content='Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.'),\n",
       "  Document(metadata={'source': 'data/doc_2.txt'}, page_content='Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.'),\n",
       "  Document(metadata={'source': 'data/doc_2.txt'}, page_content='Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.'),\n",
       "  Document(metadata={'source': 'data/doc_2.txt'}, page_content='Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications, such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.')],\n",
       " 'answer': 'Embeddings are numerical representations of words or phrases that capture their meaning and context. They are used in various applications such as information retrieval, sentiment analysis, and recommendation systems. Embeddings can be learned from large text corpora using deep learning techniques.'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the final RAG Chain\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "result = rag_chain.invoke({\"input\":\"What can you tell me about embedding?\"})\n",
    "\n",
    "result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c790d",
   "metadata": {},
   "source": [
    "## Create RAG Chain Alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5c7d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# Create custom prompt\n",
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Use the following context to answer the question.\n",
    "    If you do'nt know the answer based on the context, say you don't know.\n",
    "    Provide specific details from the context to support your answer.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f2e1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format hte output documents for the prompt\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1459dd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a type of machine learning that uses neural networks with multiple layers to learn and extract features from complex data, such as images, sound, and text. \\n\\nThis answer is supported by the context, which repeatedly states that \"Deep learning is a type of machine learning...\". This indicates that deep learning is a specific subset or category within the broader field of machine learning.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Builkd the chain using LCEL\n",
    "rag_chain_lcel = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = rag_chain_lcel.invoke(\"What is deep learning\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e44463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
