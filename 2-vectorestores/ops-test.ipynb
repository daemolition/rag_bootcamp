{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2103176",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a pwoerful technique that combines the capabilities of large\n",
    "language models with external knowledge retrievla. This notebook will walk you through building a complete RAG system using:  \n",
    "\n",
    "- LangChain: A framework fordeveloping applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitue with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b7a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb28527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crizz/python/rag_bootcamp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## Langchain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# vectorestore\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0abc72",
   "metadata": {},
   "source": [
    "## Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cf74e",
   "metadata": {},
   "source": [
    "## Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de0f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import re\n",
    "\n",
    "class SmartPDF:\n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 150):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap,\n",
    "            separators=[\" \"]\n",
    "        )\n",
    "        \n",
    "    def process_pdf(self, pdf_path: str) -> List[Document]:\n",
    "        \"\"\"Processes the pdf\"\"\"\n",
    "        \n",
    "        # Loading the PDF\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        processed_chunks = []\n",
    "        \n",
    "        for page_num, page in enumerate(pages):\n",
    "            ## Clean the text\n",
    "            cleaned_text = self._clean_text(page.page_content)\n",
    "            \n",
    "            # OPs Codes bekommen\n",
    "            ops_codes = self._get_codes(page.page_content)\n",
    "            \n",
    "            ## Skip nearly empty page\n",
    "            if len(cleaned_text.strip()) < 50:\n",
    "                continue\n",
    "            \n",
    "            chunks = self.text_splitter.create_documents(\n",
    "                texts=[cleaned_text],\n",
    "                metadatas=[{\n",
    "                    **page.metadata,\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"total_pages\": len(pages),\n",
    "                    \"chunk_method\": \"smar_pdf_processor\",\n",
    "                    \"char_count\": len(cleaned_text),\n",
    "                    \"ops_code\": ops_codes\n",
    "                }]                                 \n",
    "            )        \n",
    "            \n",
    "            processed_chunks.extend(chunks)\n",
    "            \n",
    "        return processed_chunks\n",
    "    \n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean extracted text\"\"\"\n",
    "        \n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _get_codes(self, text: str) -> Any:\n",
    "        first_line = text.strip().split(\"\\n\")[0]\n",
    "        pattern = r\"^\\s*(\\d{1,2}-\\d{2,3}(?:\\.\\d{1,3})?)\"\n",
    "        match = re.match(pattern, first_line)\n",
    "        if match:\n",
    "            code = match.group(1)\n",
    "            # Nur valide OPS-Kodes zulassen (1- bis 9- am Anfang)\n",
    "            if re.match(r\"^[1-9]-\\d{2,3}(?:\\.\\d{1,3})?$\", code):\n",
    "                return code\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad1882c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2097 chunks\n",
      "producer: LibreOffice 7.5\n",
      "creator: Writer\n",
      "creationdate: 2024-10-16T11:52:46+02:00\n",
      "author: BfArM\n",
      "moddate: 2024-10-21T17:45:24+02:00\n",
      "title: OPS Version 2025 Systematisches Verzeichnis\n",
      "source: data/ops_2025.pdf\n",
      "total_pages: 662\n",
      "page: 407\n",
      "page_label: 407\n",
      "chunk_method: smar_pdf_processor\n",
      "char_count: 2541\n",
      "ops_code: 5-903\n"
     ]
    }
   ],
   "source": [
    "pdf_processor = SmartPDF()\n",
    "\n",
    "try:\n",
    "    chunks = pdf_processor.process_pdf(\"data/ops_2025.pdf\")\n",
    "    print(f\"Processed {len(chunks)} chunks\")\n",
    "    for key, value in chunks[1254].metadata.items():\n",
    "        print(f\"{key}: {value}\")   \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c05aa2",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Embeddings Inference\n",
    "embeddings = HuggingFaceEndpointEmbeddings(model=\"http://localhost:8080\")\n",
    "\n",
    "def batched(chunks, batch_size: int = 32):\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        yield chunks[i:i + batch_size]\n",
    "\n",
    "texts = [text.page_content for text in chunks]\n",
    "all_vectors = []\n",
    "\n",
    "for batch in batched(texts, 32):\n",
    "    vecs = embeddings.embed_documents(batch)\n",
    "    all_vectors.extend(vecs)\n",
    "    \n",
    "all_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2133c43",
   "metadata": {},
   "source": [
    "## Vetorstore\n",
    "Initialize ChromaDB and Store the chunks in vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create ChromaDB vectorstore\n",
    "persist_directory=\"./chromadb-ops\"\n",
    "\n",
    "\n",
    "embedding_list = []\n",
    "\n",
    "   \n",
    "## Initialize ChromaDB\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"ops_collection\"\n",
    ")\n",
    "\n",
    "def batched(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]\n",
    "\n",
    "for batch_docs in batched(chunks, 32):  \n",
    "    \n",
    "    vector_store.add_documents(batch_docs)\n",
    "    vector_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c1be1a",
   "metadata": {},
   "source": [
    "### Test the similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fc581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'page_label': '603', 'producer': 'LibreOffice 7.5', 'moddate': '2024-10-21T17:45:24+02:00', 'total_pages': 662, 'page': 603, 'title': 'OPS Version 2025 Systematisches Verzeichnis', 'author': 'BfArM', 'char_count': 2281, 'source': 'data/ops_2025.pdf', 'chunk_method': 'smar_pdf_processor', 'creationdate': '2024-10-16T11:52:46+02:00', 'creator': 'Writer'}, page_content='9-270.1 Direkte intraperitoneale Insemination (DIPI) 9-270.x Sonstige 9-270.y N.n.bez. 9-271 Follikelpunktion und Ovumaspiration, intratubarer Gametentransfer (GIFT) 9-271.0↔ Perkutane Follikelpunktion unter sonographischer Kontrolle 9-271.1↔ Laparoskopische Ovumaspiration 9-271.2↔ Transvaginale Ovumaspiration 9-271.3↔ Laparoskopische Ovumaspiration mit intratubarem Gametentransfer (GIFT) 9-271.x↔ Sonstige 9-271.y N.n.bez. 9-272 In-vitro-Fertilisation (IVF) und Embryotransfer 9-272.0 Embryotransfer [ET] 9-272.1↔ Intratubarer Zygotentransfer [ZIFT] 603/662 OPS Version 2025'),\n",
       "  1.0078049898147583),\n",
       " (Document(metadata={'moddate': '2024-10-21T17:45:24+02:00', 'page_label': '3', 'producer': 'LibreOffice 7.5', 'creator': 'Writer', 'creationdate': '2024-10-16T11:52:46+02:00', 'char_count': 2089, 'chunk_method': 'smar_pdf_processor', 'title': 'OPS Version 2025 Systematisches Verzeichnis', 'total_pages': 662, 'page': 3, 'source': 'data/ops_2025.pdf', 'author': 'BfArM'}, page_content='Inhaltsverzeichnis Kommentar: Was ist neu im OPS Version 2025? 5 Hinweise für die Benutzung 10 Abkürzungsverzeichnis 17 1 DIAGNOSTISCHE MASSNAHMEN 24 1-10...1-10 Klinische Untersuchung 24 1-20...1-33 Untersuchung einzelner Körpersysteme 24 1-40...1-49 Biopsie ohne Inzision 31 1-50...1-58 Biopsie durch Inzision 43 1-61...1-69 Diagnostische Endoskopie 50 1-70...1-79 Funktionstests 56 1-84...1-85 Explorative diagnostische Maßnahmen 60 1-90...1-99 Andere diagnostische Maßnahmen 61 3 BILDGEBENDE DIAGNOSTIK 73 3-03...3-05 Ultraschalluntersuchungen 73 3-10...3-13 Projektionsradiographie 75 3-20...3-26 Computertomographie [CT] 76 3-30...3-31 Optische Verfahren 77 3-60...3-69 Darstellung des Gefäßsystems 78 3-70...3-76 Nuklearmedizinische diagnostische Verfahren 79 3-80...3-84 Magnetresonanztomographie [MRT] 83 3-90...3-90 Andere bildgebende Verfahren 85 3-99...3-99 Zusatzinformationen zu bildgebenden Verfahren 85 5 OPERATIONEN 86 5-01...5-05 Operationen am Nervensystem 86 5-06...5-07'),\n",
       "  1.0079354047775269),\n",
       " (Document(metadata={'source': 'data/ops_2025.pdf', 'moddate': '2024-10-21T17:45:24+02:00', 'page_label': '11', 'creationdate': '2024-10-16T11:52:46+02:00', 'creator': 'Writer', 'title': 'OPS Version 2025 Systematisches Verzeichnis', 'page': 11, 'total_pages': 662, 'author': 'BfArM', 'producer': 'LibreOffice 7.5', 'chunk_method': 'smar_pdf_processor', 'char_count': 4392}, page_content='Position „y“ nicht näher bezeichnete Operationen. Der 4-stellige Kode „Andere Operationen ... “ ist als Platzhalter für spätere Erweiterungen durch Neuentwicklungen und bisher nicht berücksichtigte Operationen gedacht. Die Textbeschreibung auf der 5. und 6. Gliederungsstelle wurde aus Gründen der Übersichtlichkeit verkürzt angegeben und enthält nur die wesentlichen Unterscheidungsmerkmale gegenüber der zugehörigen Textbeschreibung der jeweils übergeordneten Gliederungsstelle. Endständige Kodierung Es ist so spezifisch wie möglich zu verschlüsseln. Das bedeutet: 1. Zunächst wird für die dokumentierte Prozedur die passende Kategorie im OPS aufgesucht. 2. Zum Kodieren dürfen nur die endständigen (terminalen) Schlüsselnummern/Kodes einer Kategorie verwendet werden. Endständige Kodes sind solche, die keine Subkodes enthalten. 3. Von den endständigen Kodes ist derjenige zu wählen, der für die dokumentierte Prozedur als der spezifischste Kode angesehen wird. 4. Die Resteklasse „Sonstige“'),\n",
       "  1.0367664098739624)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Advanced similarity search\n",
    "\n",
    "query = \"Was meint der OPS Code 1-27\"\n",
    "\n",
    "result = vector_store.similarity_search_with_score(query, k=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2ead7",
   "metadata": {},
   "source": [
    "### Understandig similarity score\n",
    "The similarity score represents how closly related a document chunk is to your query. The scoring depends on the distance\n",
    "metric used.\n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)  \n",
    "- Score of 0 = identical vectors  \n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "\n",
    "Cosine similarity (if configured):  \n",
    "\n",
    "- Higher scores = More similar  \n",
    "- Range: -1 to 1 (1 being identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bec6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize LLM, RAG Chain, Prompt Template, Query the RAG System\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",    \n",
    "    temperature=0.2,\n",
    "    top_p=0.6,\n",
    "    num_ctx=8192, \n",
    "    reasoning=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55962764",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = llm.stream(\"Was ist unter den OPS Codes 5-38 zu finden?\")\n",
    "\n",
    "for text in test_response:\n",
    "    print(text.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230c60c",
   "metadata": {},
   "source": [
    "## Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4060ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59873157",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert vectorestore to retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwarg={\"k\":12},\n",
    "    search_type=\"similarity\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7dabc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for question-answering tasks.  \n",
    "Answer the following question **only** based on the provided context.  \n",
    "\n",
    "Rules:  \n",
    "- Use only the text from the context. Do not add any external knowledge.  \n",
    "- If the information is not contained in the context, reply with: \"I don’t know.\"  \n",
    "- Always include the OPS codes mentioned in the context.  \n",
    "- Always provide the page number(s) if available.  \n",
    "- Answer in German.  \n",
    "\n",
    "Context:  \n",
    "{context}  \n",
    "\n",
    "Question:  \n",
    "{input}  \n",
    "\n",
    "Answer format (always use this structure):  \n",
    "OPS-Code: <code(s)>  \n",
    "Seite(n): <number(s)>  \n",
    "Beschreibung:\\n \n",
    "\n",
    "<answer in German>\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f573363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='\\nYou are an assistant for question-answering tasks.  \\nAnswer the following question **only** based on the provided context.  \\n\\nRules:  \\n- Use only the text from the context. Do not add any external knowledge.  \\n- If the information is not contained in the context, reply with: \"I don’t know.\"  \\n- Always include the OPS codes mentioned in the context.  \\n- Always provide the page number(s) if available.  \\n- Answer in German.  \\n\\nContext:  \\n{context}  \\n\\nQuestion:  \\n{input}  \\n\\nAnswer format (always use this structure):  \\nOPS-Code: <code(s)>  \\nSeite(n): <number(s)>  \\nBeschreibung:\\n \\n\\n<answer in German>\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:3b', reasoning=False, num_ctx=8192, temperature=0.2, top_p=0.6)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create document chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb75137",
   "metadata": {},
   "source": [
    "**This chain**\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b44956a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPS-Code: 5-84 \n",
      "Seite(n): 386/662 \n",
      "Beschreibung: Die Restklasse „Sonstige Operationen an Muskel, Sehne, Faszie der Hand und des Handgelenkes“ enthält Kodes für verschiedene Arten von Eingriffen in diesem Bereich.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "### Create the final RAG Chain\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "result = rag_chain.invoke({\"input\":\"Auf welcher Seite finde ich Codes zu operationen?\"})\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa12025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
